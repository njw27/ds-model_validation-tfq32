{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Model-Validation:-The-Bias-Variance-Tradeoff-and-the-Train-Test-Split\" data-toc-modified-id=\"Model-Validation:-The-Bias-Variance-Tradeoff-and-the-Train-Test-Split-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Model Validation: The Bias-Variance Tradeoff and the Train-Test Split</a></span></li><li><span><a href=\"#Objectives\" data-toc-modified-id=\"Objectives-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Objectives</a></span></li><li><span><a href=\"#Motivation\" data-toc-modified-id=\"Motivation-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Motivation</a></span></li><li><span><a href=\"#The-Bias-Variance-Tradeoff\" data-toc-modified-id=\"The-Bias-Variance-Tradeoff-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>The Bias-Variance Tradeoff</a></span><ul class=\"toc-item\"><li><span><a href=\"#A-Model-Example\" data-toc-modified-id=\"A-Model-Example-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>A Model Example</a></span><ul class=\"toc-item\"><li><span><a href=\"#Model-A\" data-toc-modified-id=\"Model-A-4.1.1\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;</span>Model A</a></span></li><li><span><a href=\"#Model-B\" data-toc-modified-id=\"Model-B-4.1.2\"><span class=\"toc-item-num\">4.1.2&nbsp;&nbsp;</span>Model B</a></span></li></ul></li><li><span><a href=\"#High-Bias-vs-High-Variance\" data-toc-modified-id=\"High-Bias-vs-High-Variance-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>High-Bias vs High-Variance</a></span><ul class=\"toc-item\"><li><span><a href=\"#Bias\" data-toc-modified-id=\"Bias-4.2.1\"><span class=\"toc-item-num\">4.2.1&nbsp;&nbsp;</span>Bias</a></span></li><li><span><a href=\"#Variance\" data-toc-modified-id=\"Variance-4.2.2\"><span class=\"toc-item-num\">4.2.2&nbsp;&nbsp;</span>Variance</a></span></li><li><span><a href=\"#Balancing-Bias-and-Variance\" data-toc-modified-id=\"Balancing-Bias-and-Variance-4.2.3\"><span class=\"toc-item-num\">4.2.3&nbsp;&nbsp;</span>Balancing Bias and Variance</a></span></li></ul></li><li><span><a href=\"#Different-Models-for-King-County-Housing-Data\" data-toc-modified-id=\"Different-Models-for-King-County-Housing-Data-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Different Models for King County Housing Data</a></span></li><li><span><a href=\"#ðŸ§ -Knowledge-Check\" data-toc-modified-id=\"ðŸ§ -Knowledge-Check-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>ðŸ§  Knowledge Check</a></span></li></ul></li><li><span><a href=\"#Train-Test-Split\" data-toc-modified-id=\"Train-Test-Split-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Train-Test Split</a></span><ul class=\"toc-item\"><li><span><a href=\"#Is-the-Model-Overfitting-or-Underfitting?\" data-toc-modified-id=\"Is-the-Model-Overfitting-or-Underfitting?-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Is the Model Overfitting or Underfitting?</a></span></li><li><span><a href=\"#Exercise:-Name-that-Model!\" data-toc-modified-id=\"Exercise:-Name-that-Model!-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Exercise: Name that Model!</a></span></li><li><span><a href=\"#Should-You-Ever-Fit-on-Your-Test-Set?\" data-toc-modified-id=\"Should-You-Ever-Fit-on-Your-Test-Set?-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Should You Ever Fit on Your Test Set?</a></span></li><li><span><a href=\"#Train-Test-Split-Our-Earlier-Example\" data-toc-modified-id=\"Train-Test-Split-Our-Earlier-Example-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>Train-Test Split Our Earlier Example</a></span></li><li><span><a href=\"#Now-check-performance-on-test-data\" data-toc-modified-id=\"Now-check-performance-on-test-data-5.5\"><span class=\"toc-item-num\">5.5&nbsp;&nbsp;</span>Now check performance on test data</a></span></li><li><span><a href=\"#ðŸ§ -Knowledge-Check\" data-toc-modified-id=\"ðŸ§ -Knowledge-Check-5.6\"><span class=\"toc-item-num\">5.6&nbsp;&nbsp;</span>ðŸ§  Knowledge Check</a></span></li><li><span><a href=\"#Same-Procedure-with-a-Polynomial-Model\" data-toc-modified-id=\"Same-Procedure-with-a-Polynomial-Model-5.7\"><span class=\"toc-item-num\">5.7&nbsp;&nbsp;</span>Same Procedure with a Polynomial Model</a></span></li><li><span><a href=\"#Exercise\" data-toc-modified-id=\"Exercise-5.8\"><span class=\"toc-item-num\">5.8&nbsp;&nbsp;</span>Exercise</a></span></li></ul></li><li><span><a href=\"#k-Fold-Cross-Validation:-Even-More-Rigorous-Validation\" data-toc-modified-id=\"k-Fold-Cross-Validation:-Even-More-Rigorous-Validation-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>k-Fold Cross-Validation: Even More Rigorous Validation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Example\" data-toc-modified-id=\"Example-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Example</a></span><ul class=\"toc-item\"><li><span><a href=\"#Simple-Model\" data-toc-modified-id=\"Simple-Model-6.1.1\"><span class=\"toc-item-num\">6.1.1&nbsp;&nbsp;</span>Simple Model</a></span></li><li><span><a href=\"#More-Complex-Model\" data-toc-modified-id=\"More-Complex-Model-6.1.2\"><span class=\"toc-item-num\">6.1.2&nbsp;&nbsp;</span>More Complex Model</a></span></li><li><span><a href=\"#Medium-Complexity-Model\" data-toc-modified-id=\"Medium-Complexity-Model-6.1.3\"><span class=\"toc-item-num\">6.1.3&nbsp;&nbsp;</span>Medium-Complexity Model</a></span></li><li><span><a href=\"#Checking-Our-Models-Against-the-Holdout-Test-Set\" data-toc-modified-id=\"Checking-Our-Models-Against-the-Holdout-Test-Set-6.1.4\"><span class=\"toc-item-num\">6.1.4&nbsp;&nbsp;</span>Checking Our Models Against the Holdout Test Set</a></span><ul class=\"toc-item\"><li><span><a href=\"#Testing-Other-Models\" data-toc-modified-id=\"Testing-Other-Models-6.1.4.1\"><span class=\"toc-item-num\">6.1.4.1&nbsp;&nbsp;</span>Testing Other Models</a></span></li></ul></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Model Validation: The Bias-Variance Tradeoff and the Train-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- **Explain** the bias-variance tradeoff and the correlative notions of underfit and overfit models\n",
    "- **Describe** a train-test split and **explain** its purpose in the context of predictive statistics / machine learning\n",
    "- **Explain** the algorithm of cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "At this point, we have seen different ways to create models from our data through different linear regression techniques. That's great but just like a student practicing for a big end-of-the-year test, we want to make sure our _models_ are ready to predict on data it hasn't seen yet. We want to know if the model we made is ready to make predictions for data in the \"wild\". \n",
    "\n",
    "Usually, when our model is ready to be used in the \"real world\" we refer to this as putting our model into **production** or **deploying** our model. The data it will use to make predictions will be data its never seen before. Similar to parents sending a once teenager into the world to make it on their own, we want to make sure our model is ready for the world of new data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "But you might be thinking, how do I make sure my model I've been cultivating with my own data is ready? This is where we ***model validation*** techniques to ensure our model can generalize to data it hasn't directly seen before. Going back to our analogy of a teenager ready to leave the home, we want our teenager (model) be informed so it's not naive but also flexible enough to adjust to new situations.\n",
    "\n",
    "We'll go over how to ensure our model is ready, but first we have to discuss how our model can make errors in the context of the **bias-variance tradeoff**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# The Bias-Variance Tradeoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## A Model Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Typically we'll talk about a model as how _complex_ it is in making predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's take a look at this data with just one feature and a target:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<!--TODO: Replace with a dataset and code -->\n",
    "![](https://camo.githubusercontent.com/36a1cb13983f39fc58ecdfffb415b2258e73ba1c/68747470733a2f2f6769746875622e636f6d2f6c6561726e2d636f2d73747564656e74732f6473632d322d32342d30372d626961732d76617269616e63652d74726164652d6f66662d6f6e6c696e652d64732d73702d3030302f7261772f6d61737465722f696e6465785f66696c65732f696e6465785f375f312e706e67)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can probably picture how a good model will fit to this data. Let's look at a couple models and discuss how they're making mistakes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Model A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<!--TODO: Replace with code to implement simple model -->\n",
    "\n",
    "![](img/model_simple.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "What do we observe here? How would you describe where the model is failing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Model B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<!--TODO: Replace with code to implement complex (overfitting) model -->\n",
    "\n",
    "![](img/model_complex.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "What do we observe here? How would you describe where the model is failing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## High-Bias vs High-Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can break up how the model makes mistakes (the error) by saying there are three parts:\n",
    "\n",
    "- Error inherent of the data (noise): **irreducible error**\n",
    "- Error from being not capturing patterns (too simple): **bias**\n",
    "- Error from using patterns in the data but don't generalize well (too complex): **variance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can summarize this in an equation for the _mean squared error_ (MSE):\n",
    "\n",
    "$MSE = Bias(\\hat{y})^2 + Var(\\hat{y}) + \\sigma^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![optimal](img/optimal_bias_variance.png)\n",
    "http://scott.fortmann-roe.com/docs/BiasVariance.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**High-bias** algorithms tend to be less complex, with simple or rigid underlying structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![](img/noisy-sine-linear.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "+ They train models that are consistent, but inaccurate on average.\n",
    "+ These include linear or parametric algorithms such as regression and naive Bayes.\n",
    "+ The following sorts of difficulties could lead to high bias:\n",
    "  - We did not include the correct predictors\n",
    "  - We did not take interactions into account\n",
    "  - We missed a non-linear (polynomial) relationship"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "      \n",
    "High-bias models are generally **underfit**: The models have not picked up enough of the signal in the data. And so even though they may be consistent, they don't perform particularly well on the initial data, and so they will be consistently inaccurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "On the other hand, **high-variance** algorithms tend to be more complex, with flexible underlying structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![](img/noisy-sine-decision-tree.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "+ They train models that are accurate on average, but inconsistent.\n",
    "+ These include non-linear or non-parametric algorithms such as decision trees and nearest-neighbor models.\n",
    "+ The following sorts of difficulties could lead to high variance:\n",
    "  - We included an unreasonably large number of predictors;\n",
    "  - We created new features by squaring and cubing each feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "High variance models are **overfit**: The models have picked up on the noise as well as the signal in the data. And so even though they may perform well on the initial data, they will be inconsistently accurate on new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Balancing Bias and Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "While we build our models, we have to keep this relationship in mind.  If we build complex models, we risk overfitting our models.  Their predictions will vary greatly when introduced to new data.  If our models are too simple, the predictions as a whole will be inaccurate.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![](img/noisy-sine-third-order-polynomial.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The goal is to build a model with enough complexity to be accurate, but not too much complexity to be erratic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![](img/target.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## ðŸ§  Knowledge Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![which_model](img/which_model_is_better_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Train-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "It is hard to know if your model is too simple or complex by just using it on training data.\n",
    "\n",
    "We can _hold out_ part of our training sample, use it as a test sample, and then use it to monitor our prediction error.\n",
    "\n",
    "This allows us to evaluate whether our model has the right balance of bias/variance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src='img/testtrainsplit.png' width =550 />\n",
    "\n",
    "* **training set** â€”a subset to train a model.\n",
    "* **test set**â€”a subset to test the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/king_county.csv', index_col='id')\n",
    "\n",
    "y = df.price\n",
    "X = df[['bedrooms', 'sqft_living']]\n",
    "\n",
    "#If you don't specify test_size it will be 25% \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y,\n",
    "                                                    test_size=None,\n",
    "                                                    random_state=42 #to avoid data leakage - so observation \n",
    "                                                                #from train may leak into test if you \n",
    "                                                                #since train test split is randomized\n",
    "                                                                #want train and test reproducable\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9117000170</th>\n",
       "      <td>4</td>\n",
       "      <td>1810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6700390210</th>\n",
       "      <td>3</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7212660540</th>\n",
       "      <td>4</td>\n",
       "      <td>1720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8562780200</th>\n",
       "      <td>2</td>\n",
       "      <td>1240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7760400350</th>\n",
       "      <td>3</td>\n",
       "      <td>1280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            bedrooms  sqft_living\n",
       "id                               \n",
       "9117000170         4         1810\n",
       "6700390210         3         1600\n",
       "7212660540         4         1720\n",
       "8562780200         2         1240\n",
       "7760400350         3         1280"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2591820310</th>\n",
       "      <td>4</td>\n",
       "      <td>2070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7974200820</th>\n",
       "      <td>5</td>\n",
       "      <td>2900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7701450110</th>\n",
       "      <td>4</td>\n",
       "      <td>3770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9522300010</th>\n",
       "      <td>3</td>\n",
       "      <td>4560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9510861140</th>\n",
       "      <td>3</td>\n",
       "      <td>2550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            bedrooms  sqft_living\n",
       "id                               \n",
       "2591820310         4         2070\n",
       "7974200820         5         2900\n",
       "7701450110         4         3770\n",
       "9522300010         3         4560\n",
       "9510861140         3         2550"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X_train.head())\n",
    "display(X_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16209, 2)\n",
      "(5404, 2)\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "print(X_train.shape[0] == y_train.shape[0])\n",
    "print(X_test.shape[0] == y_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Is the Model Overfitting or Underfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "If our model is not performing well on the training  data, we are probably underfitting it.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "To know if our  model is overfitting the data, we need  to test our model on unseen data. \n",
    "We then measure our performance on the unseen data. \n",
    "\n",
    "If the model performs significantly worse on the  unseen data, it is probably  overfitting the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src='https://developers.google.com/machine-learning/crash-course/images/WorkflowWithTestSet.svg' width=500/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Exercise: Name that Model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Consider the following scenarios and describe them according to bias and variance. There are four possibilities and add whether it is potentially overfitting/underfitting or if it is a \"sweet spot\":\n",
    "\n",
    "- a. The model has low bias and high variance.\n",
    "- b. The model has high bias and low variance.\n",
    "- c. The model has both low bias and low variance.\n",
    "- d. The model has both high bias and high variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Scenario 1**: The model has a low RMSE on training and a low RMSE on test.\n",
    "<details>\n",
    "    <summary> Answer\n",
    "    </summary>\n",
    "    c. The model has both low bias and low variance.\n",
    "    </details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Scenario 2**: The model has a high $R^2$ on the training set, but a low $R^2$ on the test.\n",
    "<details>\n",
    "    <summary> Answer\n",
    "    </summary>\n",
    "    a. The model has low bias and high variance.\n",
    "    </details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Scenario 3**: The model performs well on data it is fit on and well on data it has not seen.\n",
    "<details>\n",
    "    <summary> Answer\n",
    "    </summary>\n",
    "    c. The model has both low bias and low variance.\n",
    "    </details>\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Scenario 4**: The model has a low $R^2$ on training but high on the test set.\n",
    "<details>\n",
    "    <summary> Answer\n",
    "    </summary>\n",
    "    d. The model has both high bias and high variance.\n",
    "    </details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Scenario 5**: The model leaves out many of the meaningful predictors, but is consistent across samples.\n",
    "<details>\n",
    "    <summary> Answer\n",
    "    </summary>\n",
    "    b. The model has high bias and low variance.\n",
    "    </details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Scenario 6**: The model is highly sensitive to random noise in the training set.\n",
    "<details>\n",
    "    <summary> Answer\n",
    "    </summary>\n",
    "    a. The model has low bias and high variance.\n",
    "    </details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Should You Ever Fit on Your Test Set?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![no](https://media.giphy.com/media/d10dMmzqCYqQ0/giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Never fit on test data.** If you are seeing surprisingly good results on your evaluation metrics, it might be a sign that you are accidentally training on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Train-Test Split Our Earlier Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's go back to our KC housing data without the polynomial transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7129300520</th>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6414100192</th>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5631500400</th>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2487200875</th>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1954400510</th>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               price  bedrooms  bathrooms  sqft_living  sqft_lot  floors  \\\n",
       "id                                                                         \n",
       "7129300520  221900.0         3       1.00         1180      5650     1.0   \n",
       "6414100192  538000.0         3       2.25         2570      7242     2.0   \n",
       "5631500400  180000.0         2       1.00          770     10000     1.0   \n",
       "2487200875  604000.0         4       3.00         1960      5000     1.0   \n",
       "1954400510  510000.0         3       2.00         1680      8080     1.0   \n",
       "\n",
       "            waterfront  view  condition  grade  sqft_above  sqft_basement  \n",
       "id                                                                         \n",
       "7129300520           0     0          3      7        1180              0  \n",
       "6414100192           0     0          3      7        2170            400  \n",
       "5631500400           0     0          3      6         770              0  \n",
       "2487200875           0     0          5      7        1050            910  \n",
       "1954400510           0     0          3      8        1680              0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/king_county.csv', index_col='id')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now, we create a train-test split via the `sklearn.model_selection` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y = df.price\n",
    "X = df[['bedrooms', 'sqft_living']]\n",
    "\n",
    "# Here is the convention for a traditional train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Instanstiate your linear regression object\n",
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model on the training set\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5059385369004967"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the R^2 of the training data\n",
    "lr.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-55228.54258621,    312.15699349])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "A .506 R-squared reflects a model that explains about half of the total variance in the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Now check performance on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Next, we test how well the model performs on the unseen test data. Remember, we do not fit the model again. The model has calculated the optimal parameters learning from the training set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5093504668464703"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## ðŸ§  Knowledge Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "How would you describe the bias of the model based on the above training $R^2$?\n",
    "\n",
    "<details>\n",
    "    <summary> Answer\n",
    "    </summary>\n",
    "    The difference between the train and test scores is low.\n",
    "    </details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "What does that indicate about variance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Same Procedure with a Polynomial Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7129300520</th>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6414100192</th>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5631500400</th>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2487200875</th>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1954400510</th>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               price  bedrooms  bathrooms  sqft_living  sqft_lot  floors  \\\n",
       "id                                                                         \n",
       "7129300520  221900.0         3       1.00         1180      5650     1.0   \n",
       "6414100192  538000.0         3       2.25         2570      7242     2.0   \n",
       "5631500400  180000.0         2       1.00          770     10000     1.0   \n",
       "2487200875  604000.0         4       3.00         1960      5000     1.0   \n",
       "1954400510  510000.0         3       2.00         1680      8080     1.0   \n",
       "\n",
       "            waterfront  view  condition  grade  sqft_above  sqft_basement  \n",
       "id                                                                         \n",
       "7129300520           0     0          3      7        1180              0  \n",
       "6414100192           0     0          3      7        2170            400  \n",
       "5631500400           0     0          3      6         770              0  \n",
       "2487200875           0     0          5      7        1050            910  \n",
       "1954400510           0     0          3      8        1680              0  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/king_county.csv', index_col='id')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1355</th>\n",
       "      <th>1356</th>\n",
       "      <th>1357</th>\n",
       "      <th>1358</th>\n",
       "      <th>1359</th>\n",
       "      <th>1360</th>\n",
       "      <th>1361</th>\n",
       "      <th>1362</th>\n",
       "      <th>1363</th>\n",
       "      <th>1364</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180.0</td>\n",
       "      <td>5650.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.150122e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.938778e+12</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570.0</td>\n",
       "      <td>7242.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7840000.0</td>\n",
       "      <td>7.152819e+10</td>\n",
       "      <td>1.318492e+10</td>\n",
       "      <td>2.430400e+09</td>\n",
       "      <td>4.480000e+08</td>\n",
       "      <td>2.217374e+13</td>\n",
       "      <td>4.087325e+12</td>\n",
       "      <td>7.534240e+11</td>\n",
       "      <td>1.388800e+11</td>\n",
       "      <td>2.560000e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.739198e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.515304e+11</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>40576900.0</td>\n",
       "      <td>8.103375e+09</td>\n",
       "      <td>7.022925e+09</td>\n",
       "      <td>6.086535e+09</td>\n",
       "      <td>5.274997e+09</td>\n",
       "      <td>1.215506e+12</td>\n",
       "      <td>1.053439e+12</td>\n",
       "      <td>9.129802e+11</td>\n",
       "      <td>7.912496e+11</td>\n",
       "      <td>6.857496e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680.0</td>\n",
       "      <td>8080.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.793306e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.965942e+12</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1365 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1     2       3        4     5     6     7     8     9     ...  \\\n",
       "0   1.0   3.0  1.00  1180.0   5650.0   1.0   0.0   0.0   3.0   7.0  ...   \n",
       "1   1.0   3.0  2.25  2570.0   7242.0   2.0   0.0   0.0   3.0   7.0  ...   \n",
       "2   1.0   2.0  1.00   770.0  10000.0   1.0   0.0   0.0   3.0   6.0  ...   \n",
       "3   1.0   4.0  3.00  1960.0   5000.0   1.0   0.0   0.0   5.0   7.0  ...   \n",
       "4   1.0   3.0  2.00  1680.0   8080.0   1.0   0.0   0.0   3.0   8.0  ...   \n",
       "\n",
       "         1355          1356          1357          1358          1359  \\\n",
       "0         0.0  1.150122e+10  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "1   7840000.0  7.152819e+10  1.318492e+10  2.430400e+09  4.480000e+08   \n",
       "2         0.0  2.739198e+09  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "3  40576900.0  8.103375e+09  7.022925e+09  6.086535e+09  5.274997e+09   \n",
       "4         0.0  3.793306e+10  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "\n",
       "           1360          1361          1362          1363          1364  \n",
       "0  1.938778e+12  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "1  2.217374e+13  4.087325e+12  7.534240e+11  1.388800e+11  2.560000e+10  \n",
       "2  3.515304e+11  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "3  1.215506e+12  1.053439e+12  9.129802e+11  7.912496e+11  6.857496e+11  \n",
       "4  7.965942e+12  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "\n",
       "[5 rows x 1365 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_2 = PolynomialFeatures(4)\n",
    "\n",
    "X_poly = pd.DataFrame(\n",
    "            poly_2.fit_transform(df.drop('price', axis=1))\n",
    "                      )\n",
    "\n",
    "y = df.price\n",
    "X_poly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7025512345850116"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_poly, y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)\n",
    "lr_poly = LinearRegression()\n",
    "\n",
    "# Always fit on the training set\n",
    "lr_poly.fit(X_train, y_train)\n",
    "\n",
    "lr_poly.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-54.536720695314614"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_poly.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**[This post about scaling and data leakage](https://datascience.stackexchange.com/questions/38395/standardscaler-before-and-after-splitting-data) explains that if you are going to scale your data, you should only train your scaler on the training data to prevent data leakage.**  \n",
    "\n",
    "Perform the same train-test split as shown above for the simple model, but now scale your data appropriately.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5059385369004967"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "y = df.price\n",
    "X = df[['bedrooms', 'sqft_living']]\n",
    "\n",
    "# Train test split with random_state=42 and test_size=0.2\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)\n",
    "\n",
    "# Scale appropriately on TRAINING DATA \n",
    "\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_train)\n",
    "X_preds_st_scaled = ss.transform(X_train)\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "# fit and score the model (checkout the test set if there is time)\n",
    "lr.fit(X_preds_st_scaled, y_train)\n",
    "lr.coef_\n",
    "lr.score(X_preds_st_scaled, y_train)  #this scores should be the same as the first train-split example above \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# k-Fold Cross-Validation: Even More Rigorous Validation  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Our goal of using a test set is to simulate what happens when our model attempts predictions on data it's never seen before. But there's always a chance our model will by chance perform well on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This is where we could use a more rigorous validation method and so we turn to **k-fold cross-validation**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![kfolds](img/k_folds.png)\n",
    "\n",
    "[image via sklearn](https://scikit-learn.org/stable/modules/cross_validation.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In this process, we split the dataset into a train set and holdout test sets like usual by performing a shuffling train-test split on the train set.  \n",
    "\n",
    "We then do $k$-number of _folds_ of the training data. This means we divide the training set into different sections or folds. We then take turns on using each fold as a **validation set** (or **dev set**) and train on the larger fraction. Then we calculate a validation score from the validation set the model has never seen. We repeat this process until each fold has served as a validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This process allows us to try out training our model and check to see if it is likely to overfit or underfit without touching the holdout test data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "If we think the model is looking good according to our cross-validation using the training data, we retrain the model using all of the training data. Then we can do one final evaluation using the test data. \n",
    "\n",
    "It's important that we hold onto our test data until the end and refrain from making adjustments to the model based on the test results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X = df.drop('price', axis=1)\n",
    "y = df.price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Let's create our holdout test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                                X,\n",
    "                                                y,\n",
    "                                                test_size=0.2,\n",
    "                                                random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Simple Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.04891825, 0.05092692, 0.03490686, 0.06176019, 0.0385468 ]),\n",
       " 'score_time': array([0.00161886, 0.00166106, 0.00126314, 0.00276089, 0.00316405]),\n",
       " 'test_score': array([0.58939675, 0.59024623, 0.62247064, 0.61815269, 0.58479733]),\n",
       " 'train_score': array([0.60608408, 0.60542007, 0.59746541, 0.59886644, 0.60586444])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_simple = LinearRegression()\n",
    "scores_simple = cross_validate(\n",
    "                    model_simple, X_train, y_train, cv=5, \n",
    "                    return_train_score=True\n",
    ")\n",
    "scores_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6027400889129975, 0.0037670560670530983)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean train r_2\n",
    "np.mean(scores_simple['train_score']), np.std(scores_simple['train_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6010127304502677, 0.01592487173906749)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean test r_2\n",
    "np.mean(scores_simple['test_score']), np.std(scores_simple['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.602533379449363"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit on all the training data\n",
    "model_simple.fit(X_train, y_train)\n",
    "model_simple.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### More Complex Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Test out our polynomial model\n",
    "poly_3 = PolynomialFeatures(3)\n",
    "X_poly3 = poly_3.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([2.31131625, 2.31693411, 2.2756958 , 2.03604007, 1.91766119]),\n",
       " 'score_time': array([0.00127077, 0.00098705, 0.00105214, 0.00099111, 0.00115585]),\n",
       " 'test_score': array([ 0.68876959,  0.61665975,  0.38541365,  0.62112617, -0.25850185]),\n",
       " 'train_score': array([0.6928725 , 0.70070931, 0.71077313, 0.71305421, 0.71916595])}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_poly3 = LinearRegression()\n",
    "scores_complex3 = cross_validate(\n",
    "                        model_poly3, X_poly3, y_train, cv=5, \n",
    "                        return_train_score=True\n",
    ")\n",
    "scores_complex3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7073150187567784, 0.009354819939372282)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean train r_2\n",
    "np.mean(scores_complex3['train_score']), np.std(scores_complex3['train_score']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.41069346181153943, 0.3499976571854969)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean test r_2\n",
    "np.mean(scores_complex3['test_score']), np.std(scores_complex3['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7033589903208285"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit on all the training data\n",
    "model_poly3.fit(X_poly3, y_train)\n",
    "model_poly3.score(X_poly3, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Medium-Complexity Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Test out our polynomial model\n",
    "poly_2 = PolynomialFeatures(2)\n",
    "X_poly2 = poly_2.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.37866497, 0.67976403, 0.63277388, 0.38723993, 0.38703489]),\n",
       " 'score_time': array([0.00062299, 0.00120401, 0.00067616, 0.0006609 , 0.00058317]),\n",
       " 'test_score': array([0.71440082, 0.5886194 , 0.66306261, 0.69362487, 0.63191255]),\n",
       " 'train_score': array([0.68806328, 0.69353646, 0.69956413, 0.69467419, 0.70768282])}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_poly2 = LinearRegression()\n",
    "scores_complex2 = cross_validate(\n",
    "                        model_poly2, X_poly2, y_train, cv=5, \n",
    "                        return_train_score=True\n",
    ")\n",
    "scores_complex2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.696704175441582, 0.006595914048353439)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean train r_2\n",
    "np.mean(scores_complex2['train_score']), np.std(scores_complex2['train_score']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6583240514191866, 0.04465313126535342)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean test r_2\n",
    "np.mean(scores_complex2['test_score']), np.std(scores_complex2['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6957552617273535"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_poly2.fit(X_poly2, y_train)\n",
    "model_poly2.score(X_poly2, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Checking Our Models Against the Holdout Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Once we have an acceptable model, we train our model on the entire training set and score on the test to validate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "best_model = model_poly2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.678605344170726"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remember we have to transform X_test in the same way\n",
    "best_model.score(\n",
    "    poly_2.transform(X_test),\n",
    "    y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Testing Other Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6150749892583851"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple model\n",
    "model_simple.score(\n",
    "    X_test,\n",
    "    y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6042672193696808"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remember we have to transform X_test in the same way for this model\n",
    "model_poly3.score(\n",
    "    poly_3.transform(X_test),\n",
    "    y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": "1",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "TOC",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "371px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
